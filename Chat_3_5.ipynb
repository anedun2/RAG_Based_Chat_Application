{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Based Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Python Notebook retreives the Index which is stored locally and configures chat engine to get prompts from the user and provide appropriate response which is relavent to the context (Text data in the parsed PDF files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import openai\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenAI API Key Authentication (The OpenAI API Key will be stored in the config.py file)\n",
    "openai.api_key = config.openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load index from local\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"index\")\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure chat engine #Chat engine is a high-level interface for having a conversation with your data \n",
    "chat_engine = index.as_chat_engine(verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mThought: I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is Neural Matching Models?'}\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mObservation: \n",
      "Neural matching models are a type of retrieval model that rely on soft matching between numerical text representations in order to address vocabulary mismatch problems. They are used to compute full cross attention between contextualized token representations in order to model complex matching and address both vocabulary and semantic mismatch.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mResponse: Neural matching models are a type of retrieval model that rely on soft matching between numerical text representations in order to address vocabulary mismatch problems. They are used to compute full cross attention between contextualized token representations in order to model complex matching and address both vocabulary and semantic mismatch.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Loop to have back-and-forth conversation\n",
    "while True:\n",
    "    prompt = input('Prompt: ')\n",
    "    response = chat_engine.chat(\"\"+prompt+\"\")\n",
    "    # print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
